{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_raw = pd.read_csv('./data/telco.csv')\n",
    "telco_raw['TotalCharges'] = pd.to_numeric(telco_raw['TotalCharges'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Strategies and Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "0           Electronic check          29.85         29.85     No  \n",
       "1               Mailed check          56.95       1889.50     No  \n",
       "2               Mailed check          53.85        108.15    Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75     No  \n",
       "4           Electronic check          70.70        151.65    Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of our columns contain strings. We will have to transform these strings so our model can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# telco_raw.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Separate the identifier (customer ID) and target variable (churn flag). \n",
    "\n",
    "**Step 2:** store in separate lists to use later.\n",
    "\n",
    "**Step 3:** separate categorical column names by defining a column as categorical if it has less than 10 unique values. ----- good practice to explore data to see if there are variables with more unique values.\n",
    "\n",
    "**Step 4:** remove target variable from the list so we dont' do transformations on it\n",
    "\n",
    "**Step 5:** store remaining columns named into a list called numerical. Use list comprehensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custid = ['customerID']\n",
    "target = ['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = telco_raw.nunique()[telco_raw.nunique()<10].keys().tolist()\n",
    "categorical.remove(target[0])\n",
    "numerical = [col for col in telco_raw.columns if col not in custid+target+categorical]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding: convert these variables into binary columns with ones and zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first so it wont be redundant\n",
    "telco_raw = pd.get_dummies(data=telco_raw, columns =categorical, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling Numerical Features:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize instance\n",
    "scaler = StandardScaler()\n",
    "#fit scaler to numerical columns\n",
    "scaled_numerical = scaler.fit_transform(telco_raw[numerical])\n",
    "#build df\n",
    "scaled_numerical = pd.DataFrame(scaled_numerical, columns = numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop non sclaed numerical columns\n",
    "telco_raw = telco_raw.drop(columns = numerical, axis = 1)\n",
    "#merge non numerical with the scaled numerical data\n",
    "telco = telco_raw.merge(right = scaled_numerical, how = 'left', left_index = True, right_index = True)\n",
    "telco.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Modeling Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to building Supervised learning model\n",
    "- **Split** data to training and testing. This is important as we want to \"train\" the model on one set of data, and then measure its performance on unseen values or testing dataset to make sure it works well on unseed data.\n",
    "- **Intialize** the model\n",
    "- **Fit** the model on the training data\n",
    "- **Predict** values on the testing data\n",
    "- **Measure** model performance on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = telco.loc[:, ~telco.columns.isin(['customerID', 'Churn', 'TotalCharges'])]\n",
    "Y = telco['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7093287827076223"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example 1\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size = 0.25) #defines the percentage to be reserved to testing dataset\n",
    "mytree=tree.DecisionTreeClassifier()\n",
    "treemodel = mytree.fit(train_X, train_Y)\n",
    "pred_Y = treemodel.predict(test_X)\n",
    "accuracy_score(test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datacamp example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "#example 2 - advance\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size = 0.25) #defines the percentage to be reserved to testing dataset\n",
    "#ensure train df has 75%\n",
    "print(train_X.shape[0]/X.shape[0])\n",
    "print(test_X.shape[0]/ X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7861205915813424"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intialize, fit, predict, \n",
    "mytree = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "treemodel = mytree.fit(train_X, train_Y)\n",
    "pred_Y = treemodel.predict(test_X)\n",
    "#measure model perfomrance on testing data\n",
    "accuracy_score(test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict Churn WIth Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.82\n",
      "Test accuracy:  0.768\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth = 7, criterion = 'gini', splitter = 'best')\n",
    "#fit and predict\n",
    "clf = clf.fit(train_X, train_Y)\n",
    "pred_Y = clf.predict(test_X)\n",
    "# Print accuracy values\n",
    "print(\"Training accuracy: \", np.round(clf.score(train_X, train_Y), 3)) \n",
    "print(\"Test accuracy: \", np.round(accuracy_score(test_Y, pred_Y), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised\n",
    "- **Initialize** the model\n",
    "- **Fit** the model\n",
    "- **Assign** cluster values\n",
    "- **Explore** Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 3)\n",
    "kmeans.fit(telco.loc[:, ~telco.columns.isin(['customerID', 'Churn', 'TotalCharges'])])\n",
    "# telco.assign(Cluster = kmeans.labels_)\n",
    "# telco.groupby().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Predictions and Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No', 'Yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print unique Churn values\n",
    "set(telco['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "No     73.421502\n",
       "Yes    26.578498\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate ratio size of churn groups\n",
    "telco.groupby(['Churn']).size() / telco.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(telco, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['Churn']\n",
    "custid = ['customerID']\n",
    "cols = [col for col in telco.columns if col not in custid + target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build training and testing datasets\n",
    "train_X = train[cols]\n",
    "train_Y = train[target]\n",
    "test_X = test[cols]\n",
    "test_Y = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Churn with Logistic Regression -- revisit modeling steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Metrics\n",
    "- **Accuracy:** The % of correctly predicted labels\n",
    "- **Precision:** The % of total model's positive class predictions that were correctly classified\n",
    "- **Recall:** The % of total positive class samples that were correctly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8104\n",
      "Test accuracy: 0.8026\n"
     ]
    }
   ],
   "source": [
    "pred_train_Y = logreg.predict(train_X)\n",
    "pred_test_Y = logreg.predict(test_X)\n",
    "train_accuracy = accuracy_score(train_Y, pred_train_Y)\n",
    "test_accuracy = accuracy_score(test_Y, pred_test_Y)\n",
    "print('Training accuracy:', round(train_accuracy, 4))\n",
    "print('Test accuracy:', round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training precision: 0.6739, Training recall: 0.5536\n",
      "Testing precision: 0.6533, Testing recall: 0.5544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "train_precision =  round(precision_score(train_Y, pred_train_Y, pos_label=\"Yes\"), 4)\n",
    "test_precision = round(precision_score(test_Y, pred_test_Y,  pos_label=\"Yes\"), 4)\n",
    "train_recall = round(recall_score(train_Y, pred_train_Y,  pos_label=\"Yes\"), 4)\n",
    "test_recall = round(recall_score(test_Y, pred_test_Y,  pos_label=\"Yes\"), 4)\n",
    "print('Training precision: {}, Training recall: {}'.format(train_precision, train_recall))\n",
    "print('Testing precision: {}, Testing recall: {}'.format(test_precision, test_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 (aka lasso) regularization and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty = 'l1', C = 0.1, solver = 'liblinear')\n",
    "logreg.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\blytle\\Anaconda3221\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Non-Zero Coeffs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.802048</td>\n",
       "      <td>0.650873</td>\n",
       "      <td>0.556503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.799204</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.550107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.800910</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.552239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.802617</td>\n",
       "      <td>0.655612</td>\n",
       "      <td>0.547974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0500</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.798066</td>\n",
       "      <td>0.651596</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.800341</td>\n",
       "      <td>0.673529</td>\n",
       "      <td>0.488273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.800341</td>\n",
       "      <td>0.697987</td>\n",
       "      <td>0.443497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.789534</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.319829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.733220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  Non-Zero Coeffs  Accuracy  Precision    Recall\n",
       "0  1.0000             22.0  0.802048   0.650873  0.556503\n",
       "1  0.5000             21.0  0.799204   0.645000  0.550107\n",
       "2  0.2500             20.0  0.800910   0.649123  0.552239\n",
       "3  0.1000             19.0  0.802617   0.655612  0.547974\n",
       "4  0.0500             14.0  0.798066   0.651596  0.522388\n",
       "5  0.0250             13.0  0.800341   0.673529  0.488273\n",
       "6  0.0100              7.0  0.800341   0.697987  0.443497\n",
       "7  0.0050              3.0  0.789534   0.746269  0.319829\n",
       "8  0.0025              2.0  0.733220   0.000000  0.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking which C values are best\n",
    "C = [1, .5, .25, .1, .05, .025, .01, .005, .0025]\n",
    "l1_metrics = np.zeros((len(C), 5))\n",
    "l1_metrics[:,0] = C\n",
    "for index in range(0, len(C)):\n",
    "    logreg = LogisticRegression(penalty='l1', C=C[index], solver='liblinear')\n",
    "    logreg.fit(train_X, train_Y)\n",
    "    pred_test_Y = logreg.predict(test_X)\n",
    "    l1_metrics[index,1] = np.count_nonzero(logreg.coef_)\n",
    "    l1_metrics[index,2] = accuracy_score(test_Y, pred_test_Y)\n",
    "    l1_metrics[index,3] = precision_score(test_Y, pred_test_Y, pos_label=\"Yes\")\n",
    "    l1_metrics[index,4] = recall_score(test_Y, pred_test_Y, pos_label=\"Yes\")\n",
    "\n",
    "col_names = ['C','Non-Zero Coeffs','Accuracy','Precision','Recall']\n",
    "pd.DataFrame(l1_metrics, columns = col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict Churn with Decision Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "mytree = DecisionTreeClassifier()\n",
    "treemodel = mytree.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9981\n",
      "Test Accurracy: 0.7162\n"
     ]
    }
   ],
   "source": [
    "pred_train_Y = mytree.predict(train_X)\n",
    "pred_test_Y = mytree.predict(test_X)\n",
    "train_accuracy = accuracy_score(train_Y, pred_train_Y)\n",
    "test_accuracy = accuracy_score(test_Y, pred_test_Y)\n",
    "print('Training Accuracy:', round(train_accuracy, 4))\n",
    "print('Test Accurracy:', round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the tree memorized the patterns and rules for the training data almost perfectly, but failed to generalize the rules for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training precision: 0.9993, Training recall: 0.9936\n",
      "Testing precision: 0.4696, Testing recall: 0.4947\n"
     ]
    }
   ],
   "source": [
    "train_precision =  round(precision_score(train_Y, pred_train_Y, pos_label=\"Yes\"), 4)\n",
    "test_precision = round(precision_score(test_Y, pred_test_Y,  pos_label=\"Yes\"), 4)\n",
    "train_recall = round(recall_score(train_Y, pred_train_Y,  pos_label=\"Yes\"), 4)\n",
    "test_recall = round(recall_score(test_Y, pred_test_Y,  pos_label=\"Yes\"), 4)\n",
    "print('Training precision: {}, Training recall: {}'.format(train_precision, train_recall))\n",
    "print('Testing precision: {}, Testing recall: {}'.format(test_precision, test_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree Depth Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_list = list(range(2,15))\n",
    "depth_tuning = np.zeros((len(depth_list), 4))\n",
    "depth_tuning[:,0] = depth_list\n",
    "for index in range(len(depth_list)):\n",
    "    mytree = DecisionTreeClassifier(max_depth=depth_list[index])\n",
    "    mytree.fit(train_X, train_Y)\n",
    "    pred_test_Y = mytree.predict(test_X)\n",
    "    depth_tuning[index,1] = accuracy_score(test_Y, pred_test_Y)\n",
    "    depth_tuning[index,2] = precision_score(test_Y, pred_test_Y,pos_label=\"Yes\")\n",
    "    depth_tuning[index,3] = recall_score(test_Y, pred_test_Y,pos_label=\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Max_Depth  Accuracy  Precision    Recall\n",
      "0         2.0  0.788965   0.664430  0.422175\n",
      "1         3.0  0.788965   0.664430  0.422175\n",
      "2         4.0  0.782708   0.680498  0.349680\n",
      "3         5.0  0.786689   0.658784  0.415778\n",
      "4         6.0  0.781570   0.622478  0.460554\n",
      "5         7.0  0.788965   0.621891  0.533049\n",
      "6         8.0  0.763936   0.573370  0.449893\n",
      "7         9.0  0.764505   0.563805  0.518124\n",
      "8        10.0  0.752560   0.540670  0.481876\n",
      "9        11.0  0.759386   0.548936  0.550107\n",
      "10       12.0  0.750853   0.533191  0.530917\n",
      "11       13.0  0.732651   0.499022  0.543710\n",
      "12       14.0  0.728669   0.491770  0.509595\n"
     ]
    }
   ],
   "source": [
    "col_names = ['Max_Depth','Accuracy','Precision','Recall']\n",
    "print(pd.DataFrame(depth_tuning, columns=col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifying and Interpreting Churn Drivers**\n",
    "- log odds is difficult to interpret \n",
    "- solution: calculate expotent of the coeffiencets.\n",
    "- This gives us the change in ODDS associated with 1 unite increase in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported = tree.export_graphviz(decision_tree = mytree, out_file = None,\n",
    "                               feature_names = cols, precision = 1,\n",
    "                               class_names = ['Not churn', 'Churn'], filled= True)\n",
    "graph = graphviz.Source(exported)\n",
    "# display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Feature  Coefficient  Exp_Coefficient\n",
      "27          tenure    -0.403825         0.667761\n",
      "28  MonthlyCharges     0.128546         1.137173\n"
     ]
    }
   ],
   "source": [
    "coefficients = pd.concat([pd.DataFrame(train_X.columns),\n",
    "                          pd.DataFrame(np.transpose(logreg.coef_))],axis = 1)\n",
    "coefficients.columns = ['Feature','Coefficient']\n",
    "coefficients['Exp_Coefficient'] = np.exp(coefficients['Coefficient'])\n",
    "coefficients = coefficients[coefficients['Coefficient']!=0]\n",
    "print(coefficients.sort_values(by=['Coefficient']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLV BASICS\n",
    "**No Dataset Available**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Calculate monthly spend per customer:* -monthly_revenue = online.groupby(['customerID', 'InvoiceMonth'])['TotalSum'].sum().mean()\n",
    "- *Calculate average monthly spend* : monthly_revenue = np.mean(monthly_revenue)\n",
    "- lifespan_months = 36\n",
    "- clv_basic = monthly_revenue * lifepsan_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Granular CLV Calculation - invoice level data points to calculate the granular customer lifetime value**\n",
    "- *Calculate average Reveune per invoice* : - revenue_per_purchase = online.groupby(['InvoiceNo'])['TotalSum'].mean().mean()\n",
    "- *Calculate average number of unique invoices per customer per month* - freq = online.groupby(['CustomerID', 'InvoiceMonth'])['InvoiceNo'].nunique().mean()\n",
    "- lifespan_months = 26\n",
    "- clv_grannular = revenue_per_purchase * freq * lifespan_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traditional CLV Calculation -  does not require lifespan to be defined, and instead uses retention to churn rate to assess customer life expectancy.**\n",
    "- *calculate monthly spend per customer:* monthly_revenue = online.groupby(['customerID', 'InvoiceMonth'])['TotalSum'].sum().mean()\n",
    "- *calculate average monthly retention rate:* retention_rate = retention.iloc[:,1:].mean().mean()\n",
    "- *average monthly churn rate:* churn_rate = 1 - retention_rate\n",
    "- clv_traditional = monthly_revenue * (retention_rate/churn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUSTOMER SEGMENTATION BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wholesale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-ef6b88565376>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwholesale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#get the statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0maverages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwholesale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mst_dev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwholesale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwholesale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wholesale' is not defined"
     ]
    }
   ],
   "source": [
    "wholesale.agg(['mean', 'std']).round(0)\n",
    "#get the statistics\n",
    "averages = wholesale.mean()\n",
    "st_dev = wholesale.std()\n",
    "x_names = wholesale.columns\n",
    "x_ix = np.arange(wholesale.shape[1])\n",
    "\n",
    "plt.bar(x_ix-0.2, averages, color = 'grey', label = 'Average', width = 0.4)\n",
    "plt.bar(x_i+0.2, st_dv, color = 'orange', label= 'Standard Deviation', width = 0.4)\n",
    "plt.xticks(x_ix, x_names, rotation = 90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unskewing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1 - log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wholesale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-697939c911f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwholesale_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwholesale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwholesale_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiag_kind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'kde'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wholesale' is not defined"
     ]
    }
   ],
   "source": [
    "wholesale_log = np.log(wholesale)\n",
    "sns.pairplot(wholesale_log, diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2 - Box Cox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wholesale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-858ee39e0e67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx_boxcox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mwholesale_boxcox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwholesale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxcox_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwholesale_boxcox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiag_kind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'kde'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wholesale' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "def boxcox_df(x):\n",
    "    x_boxcox, _ = stats.boxcox(x)\n",
    "    return x_boxcox\n",
    "\n",
    "wholesale_boxcox = wholesale.apply(boxcox_df, axis = 0)\n",
    "sns.pairplot(wholesale_boxcox, diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data - expected for kmeans method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wholesale_boxcox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-ff5f42a25947>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwholesale_boxcox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mwholesale_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwholesale_boxcox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m wholesale_scaled_df = pd.DataFrame(data = wholesale_scaled, index = wholesale_boxcox.index,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wholesale_boxcox' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(wholesale_boxcox)\n",
    "wholesale_scaled = scaler.transform(wholesale_boxcox)\n",
    "wholesale_scaled_df = pd.DataFrame(data = wholesale_scaled, index = wholesale_boxcox.index,\n",
    "                                  columns = wholesale_boxcox.columns)\n",
    "wholesale_scaled_df.agg(['mean', 'std']).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUILD CUSTOMER PRODUCT SEGMENTATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation with Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wholesale_scaled_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-3e93cbd98526>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwholesale_scaled_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mwholesale_kmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwholesale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wholesale_scaled_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = k)\n",
    "kmeans.fit(wholesale_scaled_df)\n",
    "wholesale_kmeans = wholesale.assign(segment = kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wholesale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-cf10574fe865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwholesale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcompontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompontents_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwholesale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wholesale' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(k)\n",
    "nmf.fit(wholesale)\n",
    "compontents = pd.DataFrame(nmf.compontents_, columns = wholesale.columns)\n",
    "\n",
    "#extracting segment assignment:\n",
    "segments_weights = pd.DataFrame(nmf.transform(wholesale, columns = compontents.index))\n",
    "segments_weights.index = wholesale.index\n",
    "wholesale_nmf = wholesale.assign(segment = segment_weights.idxmax(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate sum of squared errors and plot results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_cluslters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-940921043b9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_cluslters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m333\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwholesale_scaled_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3221\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_cluslters'"
     ]
    }
   ],
   "source": [
    "sse = {}\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_cluslters = k, random_state = 333)\n",
    "    kmeans.fit(wholesale_scaled_df)\n",
    "    sse[k] = kmeans.inertia_\n",
    "    \n",
    "plt.title('Elbow criterion method chart')\n",
    "sns.pointplot(x=list(sse.keys()), y = list(sse.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF SEGMENTATION AVERAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wholesale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-78a202c4dc9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#create W Matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwholesale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompontents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwholesale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#assign column name where the corresponding values is the largest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwholesale_nmf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwholesale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wholesale' is not defined"
     ]
    }
   ],
   "source": [
    "#create W Matrix\n",
    "w = pd.DataFrame(data = nmf.transform(wholesale), columns = compontents.index)\n",
    "w.index = wholesale.index\n",
    "#assign column name where the corresponding values is the largest\n",
    "wholesale_nmf3 = wholesale.assign(segment = w.idxmax(axis = 1))\n",
    "#calculate the average column values per each segment\n",
    "nmf3_averages = wholesale_nmf3.groupby('segment').mean().round(0)\n",
    "#plot the average values as a heatmap\n",
    "sns.heatmap(nmf3.averages.T, cmap = 'YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize and interprete segmentation solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wholesale_kmeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-6c394ca3337f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkmeans_averages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwholesale_kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'segment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmeans_averages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'YlGuBu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#plot average NMF segmentation attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wholesale_kmeans' is not defined"
     ]
    }
   ],
   "source": [
    "kmeans_averages = wholesale_kmeans.groupby(['segment']).mean().round(0)\n",
    "\n",
    "sns.heatmap(kmeans_averages.T, smap = 'YlGuBu')\n",
    "\n",
    "#plot average NMF segmentation attributes\n",
    "nmf_averages = wholesale_nmf.groupby('segment').mean()\n",
    "sns.heatmap(nmf_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
